/**
 * Parser tests
 */

import { describe, it, expect } from 'vitest';
import { Lexer } from '../parser/lexer';
import { Parser } from '../parser/parser';
import { ASTToGraphConverter } from '../parser/ast-to-graph';

describe('IOC Parser', () => {
  it('should parse simple pipeline', () => {
    const source = `
input numbers: number[]
positive = filter numbers where x > 0
doubled = map positive with x * 2
total = reduce doubled by sum
output total
    `.trim();

    const lexer = new Lexer(source);
    const tokens = lexer.tokenize();

    const parser = new Parser(tokens);
    const ast = parser.parse();

    expect(ast.statements).toHaveLength(5);
    expect(ast.statements[0]!.type).toBe('input');
    expect(ast.statements[1]!.type).toBe('filter');
    expect(ast.statements[2]!.type).toBe('map');
    expect(ast.statements[3]!.type).toBe('reduce');
    expect(ast.statements[4]!.type).toBe('output');
  });

  it('should parse property access', () => {
    const source = `
input users: object[]
adults = filter users where x.age >= 18
output adults
    `.trim();

    const lexer = new Lexer(source);
    const tokens = lexer.tokenize();

    const parser = new Parser(tokens);
    const ast = parser.parse();

    const filterStmt = ast.statements[1];
    expect(filterStmt!.type).toBe('filter');
    if (filterStmt!.type === 'filter') {
      expect(filterStmt!.predicate.type).toBe('property');
    }
  });

  it('should compile to SafeGraph and execute', () => {
    const source = `
input numbers: number[]
doubled = map numbers with x * 2
output doubled
    `.trim();

    const lexer = new Lexer(source);
    const tokens = lexer.tokenize();

    const parser = new Parser(tokens);
    const ast = parser.parse();

    const converter = new ASTToGraphConverter();
    const graph = converter.convert(ast);

    const compiledFn = graph.compile();
    const result = compiledFn([1, 2, 3, 4, 5]);

    expect(result).toEqual([2, 4, 6, 8, 10]);
  });

  it('should handle full pipeline with filter, map, reduce', () => {
    const source = `
input numbers: number[]
positive = filter numbers where x > 0
doubled = map positive with x * 2
total = reduce doubled by sum
output total
    `.trim();

    const lexer = new Lexer(source);
    const tokens = lexer.tokenize();

    const parser = new Parser(tokens);
    const ast = parser.parse();

    const converter = new ASTToGraphConverter();
    const graph = converter.convert(ast);

    const compiledFn = graph.compile();
    const result = compiledFn([1, -2, 3, -4, 5]);

    // Filter: [1, 3, 5]
    // Map *2: [2, 6, 10]
    // Sum: 18
    expect(result).toBe(18);
  });

  it('should handle string operations', () => {
    const source = `
input words: string[]
uppercased = map words with uppercase(x)
output uppercased
    `.trim();

    const lexer = new Lexer(source);
    const tokens = lexer.tokenize();

    const parser = new Parser(tokens);
    const ast = parser.parse();

    const converter = new ASTToGraphConverter();
    const graph = converter.convert(ast);

    const compiledFn = graph.compile();
    const result = compiledFn(['hello', 'world']);

    expect(result).toEqual(['HELLO', 'WORLD']);
  });
});

describe('Lexer - Token Generation', () => {
  describe('Keywords', () => {
    it('should tokenize all keywords correctly', () => {
      const keywords = 'input output filter map reduce where with by if then else let and or not';
      const lexer = new Lexer(keywords);
      const tokens = lexer.tokenize();

      expect(tokens[0]!.type).toBe('INPUT');
      expect(tokens[1]!.type).toBe('OUTPUT');
      expect(tokens[2]!.type).toBe('FILTER');
      expect(tokens[3]!.type).toBe('MAP');
      expect(tokens[4]!.type).toBe('REDUCE');
      expect(tokens[5]!.type).toBe('WHERE');
      expect(tokens[6]!.type).toBe('WITH');
      expect(tokens[7]!.type).toBe('BY');
      expect(tokens[8]!.type).toBe('IF');
      expect(tokens[9]!.type).toBe('THEN');
      expect(tokens[10]!.type).toBe('ELSE');
      expect(tokens[11]!.type).toBe('LET');
      expect(tokens[12]!.type).toBe('AND');
      expect(tokens[13]!.type).toBe('OR');
      expect(tokens[14]!.type).toBe('NOT');
    });

    it('should tokenize boolean literals', () => {
      const lexer = new Lexer('true false');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.type).toBe('BOOLEAN');
      expect(tokens[0]!.value).toBe('true');
      expect(tokens[1]!.type).toBe('BOOLEAN');
      expect(tokens[1]!.value).toBe('false');
    });
  });

  describe('Operators', () => {
    it('should tokenize comparison operators', () => {
      const lexer = new Lexer('> < >= <= == !=');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.type).toBe('GT');
      expect(tokens[1]!.type).toBe('LT');
      expect(tokens[2]!.type).toBe('GTE');
      expect(tokens[3]!.type).toBe('LTE');
      expect(tokens[4]!.type).toBe('EQ');
      expect(tokens[5]!.type).toBe('NEQ');
    });

    it('should tokenize arithmetic operators', () => {
      const lexer = new Lexer('+ - * / %');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.type).toBe('PLUS');
      expect(tokens[1]!.type).toBe('MINUS');
      expect(tokens[2]!.type).toBe('STAR');
      expect(tokens[3]!.type).toBe('SLASH');
      expect(tokens[4]!.type).toBe('PERCENT');
    });

    it('should tokenize assignment operator', () => {
      const lexer = new Lexer('x = 5');
      const tokens = lexer.tokenize();

      expect(tokens[1]!.type).toBe('ASSIGN');
    });

    it('should tokenize dot operator', () => {
      const lexer = new Lexer('x.property');
      const tokens = lexer.tokenize();

      expect(tokens[1]!.type).toBe('DOT');
    });
  });

  describe('Delimiters', () => {
    it('should tokenize parentheses', () => {
      const lexer = new Lexer('(x)');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.type).toBe('LPAREN');
      expect(tokens[2]!.type).toBe('RPAREN');
    });

    it('should tokenize brackets', () => {
      const lexer = new Lexer('[1, 2, 3]');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.type).toBe('LBRACKET');
      expect(tokens[6]!.type).toBe('RBRACKET');
    });

    it('should tokenize colons and commas', () => {
      const lexer = new Lexer('name: string, age: number');
      const tokens = lexer.tokenize();

      expect(tokens[1]!.type).toBe('COLON');
      expect(tokens[3]!.type).toBe('COMMA');
    });
  });

  describe('Literals', () => {
    it('should tokenize integers', () => {
      const lexer = new Lexer('42');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.type).toBe('NUMBER');
      expect(tokens[0]!.value).toBe('42');
    });

    it('should tokenize floating point numbers', () => {
      const lexer = new Lexer('3.14159');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.type).toBe('NUMBER');
      expect(tokens[0]!.value).toBe('3.14159');
    });

    it('should tokenize identifiers', () => {
      const lexer = new Lexer('myVariable _private data123');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.type).toBe('IDENTIFIER');
      expect(tokens[0]!.value).toBe('myVariable');
      expect(tokens[1]!.type).toBe('IDENTIFIER');
      expect(tokens[1]!.value).toBe('_private');
      expect(tokens[2]!.type).toBe('IDENTIFIER');
      expect(tokens[2]!.value).toBe('data123');
    });

    it('should tokenize double-quoted strings', () => {
      const lexer = new Lexer('"hello world"');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.type).toBe('STRING');
      expect(tokens[0]!.value).toBe('hello world');
    });

    it('should tokenize single-quoted strings', () => {
      const lexer = new Lexer("'hello world'");
      const tokens = lexer.tokenize();

      expect(tokens[0]!.type).toBe('STRING');
      expect(tokens[0]!.value).toBe('hello world');
    });

    it('should handle escape sequences in strings', () => {
      const lexer = new Lexer('"line1\\nline2\\ttab"');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.type).toBe('STRING');
      expect(tokens[0]!.value).toBe('line1\nline2\ttab');
    });

    it('should throw on unterminated strings', () => {
      const lexer = new Lexer('"unterminated');
      expect(() => lexer.tokenize()).toThrow('Unterminated string');
    });
  });

  describe('Comments and Whitespace', () => {
    it('should skip comments', () => {
      const lexer = new Lexer('x # this is a comment\ny');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.value).toBe('x');
      expect(tokens[1]!.type).toBe('NEWLINE');
      expect(tokens[2]!.value).toBe('y');
    });

    it('should skip whitespace', () => {
      const lexer = new Lexer('  x   \t  y  ');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.value).toBe('x');
      expect(tokens[1]!.value).toBe('y');
    });

    it('should track line numbers correctly', () => {
      const lexer = new Lexer('line1\nline2\nline3');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.line).toBe(1);
      expect(tokens[1]!.line).toBe(1);
      expect(tokens[2]!.line).toBe(2);
      expect(tokens[3]!.line).toBe(2);
      expect(tokens[4]!.line).toBe(3);
    });

    it('should track column numbers correctly', () => {
      const lexer = new Lexer('abc def');
      const tokens = lexer.tokenize();

      expect(tokens[0]!.column).toBe(1);
      expect(tokens[1]!.column).toBe(5);
    });
  });

  describe('Edge Cases', () => {
    it('should handle empty input', () => {
      const lexer = new Lexer('');
      const tokens = lexer.tokenize();

      expect(tokens).toHaveLength(1);
      expect(tokens[0]!.type).toBe('EOF');
    });

    it('should handle only whitespace', () => {
      const lexer = new Lexer('   \t\n  ');
      const tokens = lexer.tokenize();

      expect(tokens[tokens.length - 1]!.type).toBe('EOF');
    });

    it('should throw on unexpected characters', () => {
      const lexer = new Lexer('$@!');
      expect(() => lexer.tokenize()).toThrow('Unexpected character');
    });

    it('should handle newlines correctly', () => {
      const lexer = new Lexer('line1\nline2');
      const tokens = lexer.tokenize();

      expect(tokens[1]!.type).toBe('NEWLINE');
    });
  });
});

describe('Parser - Statement Parsing', () => {
  describe('Input Declarations', () => {
    it('should parse input without type annotation', () => {
      const source = 'input data';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      expect(ast.statements).toHaveLength(1);
      expect(ast.statements[0]!.type).toBe('input');
      if (ast.statements[0]!.type === 'input') {
        expect(ast.statements[0].name).toBe('data');
        expect(ast.statements[0].dataType).toBeUndefined();
      }
    });

    it('should parse input with type annotation', () => {
      const source = 'input numbers: number[]';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      expect(ast.statements[0]!.type).toBe('input');
      if (ast.statements[0]!.type === 'input') {
        expect(ast.statements[0].name).toBe('numbers');
        expect(ast.statements[0].dataType).toBe('number[]');
      }
    });

    it('should parse input with object type', () => {
      const source = 'input users: object[]';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      if (ast.statements[0]!.type === 'input') {
        expect(ast.statements[0].dataType).toBe('object[]');
      }
    });
  });

  describe('Filter Statements', () => {
    it('should parse filter with simple comparison', () => {
      const source = 'filtered = filter data where x > 10';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      expect(ast.statements[0]!.type).toBe('filter');
      if (ast.statements[0]!.type === 'filter') {
        expect(ast.statements[0].target).toBe('filtered');
        expect(ast.statements[0].source).toBe('data');
        expect(ast.statements[0].predicate.type).toBe('comparison');
      }
    });

    it('should parse filter with all comparison operators', () => {
      const operators = [
        ['x > 5', 'gt'],
        ['x < 5', 'lt'],
        ['x >= 5', 'gte'],
        ['x <= 5', 'lte'],
        ['x == 5', 'eq'],
        ['x != 5', 'neq'],
      ];

      operators.forEach(([expr, expectedOp]) => {
        const source = `filtered = filter data where ${expr}`;
        const lexer = new Lexer(source);
        const parser = new Parser(lexer.tokenize());
        const ast = parser.parse();

        if (ast.statements[0]!.type === 'filter') {
          const predicate = ast.statements[0].predicate;
          if (predicate.type === 'comparison') {
            expect(predicate.operator).toBe(expectedOp);
          }
        }
      });
    });

    it('should parse filter with property access', () => {
      const source = 'adults = filter users where x.age >= 18';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      if (ast.statements[0]!.type === 'filter') {
        const predicate = ast.statements[0].predicate;
        expect(predicate.type).toBe('property');
        if (predicate.type === 'property') {
          expect(predicate.property).toBe('age');
          expect(predicate.operator).toBe('gte');
          expect(predicate.value).toBe(18);
        }
      }
    });

    it('should parse filter with string comparison', () => {
      const source = 'filtered = filter users where x.name == "Alice"';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      if (ast.statements[0]!.type === 'filter') {
        const predicate = ast.statements[0].predicate;
        if (predicate.type === 'property') {
          expect(predicate.value).toBe('Alice');
        }
      }
    });

    it('should parse filter with boolean comparison', () => {
      const source = 'filtered = filter users where x.active == true';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      if (ast.statements[0]!.type === 'filter') {
        const predicate = ast.statements[0].predicate;
        if (predicate.type === 'property') {
          expect(predicate.value).toBe(true);
        }
      }
    });
  });

  describe('Map Statements', () => {
    it('should parse map with arithmetic operation', () => {
      const source = 'doubled = map numbers with x * 2';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      expect(ast.statements[0]!.type).toBe('map');
      if (ast.statements[0]!.type === 'map') {
        expect(ast.statements[0].target).toBe('doubled');
        expect(ast.statements[0].source).toBe('numbers');
        expect(ast.statements[0].transform.type).toBe('arithmetic');
      }
    });

    it('should parse map with all arithmetic operators', () => {
      const operators = [
        ['x * 2', 'multiply'],
        ['x + 2', 'add'],
        ['x - 2', 'subtract'],
        ['x / 2', 'divide'],
        ['x % 2', 'mod'],
      ];

      operators.forEach(([expr, expectedOp]) => {
        const source = `result = map data with ${expr}`;
        const lexer = new Lexer(source);
        const parser = new Parser(lexer.tokenize());
        const ast = parser.parse();

        if (ast.statements[0]!.type === 'map') {
          const transform = ast.statements[0].transform;
          if (transform.type === 'arithmetic') {
            expect(transform.operator).toBe(expectedOp);
            expect(transform.value).toBe(2);
          }
        }
      });
    });

    it('should parse map with property access', () => {
      const source = 'names = map users with x.name';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      if (ast.statements[0]!.type === 'map') {
        const transform = ast.statements[0].transform;
        expect(transform.type).toBe('property');
        if (transform.type === 'property') {
          expect(transform.property).toBe('name');
        }
      }
    });

    it('should parse map with string functions', () => {
      const functions = ['uppercase', 'lowercase', 'trim'];

      functions.forEach((fn) => {
        const source = `result = map data with ${fn}(x)`;
        const lexer = new Lexer(source);
        const parser = new Parser(lexer.tokenize());
        const ast = parser.parse();

        if (ast.statements[0]!.type === 'map') {
          const transform = ast.statements[0].transform;
          expect(transform.type).toBe('string');
          if (transform.type === 'string') {
            expect(transform.operation).toBe(fn);
          }
        }
      });
    });
  });

  describe('Reduce Statements', () => {
    it('should parse reduce with sum', () => {
      const source = 'total = reduce numbers by sum';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      expect(ast.statements[0]!.type).toBe('reduce');
      if (ast.statements[0]!.type === 'reduce') {
        expect(ast.statements[0].target).toBe('total');
        expect(ast.statements[0].source).toBe('numbers');
        expect(ast.statements[0].operation).toBe('sum');
      }
    });

    it('should parse all reduction operations', () => {
      const operations = [
        'sum',
        'product',
        'max',
        'min',
        'average',
        'count',
        'first',
        'last',
        'join',
      ];

      operations.forEach((op) => {
        const source = `result = reduce data by ${op}`;
        const lexer = new Lexer(source);
        const parser = new Parser(lexer.tokenize());
        const ast = parser.parse();

        if (ast.statements[0]!.type === 'reduce') {
          expect(ast.statements[0].operation).toBe(op);
        }
      });
    });

    it('should throw on unknown reduction operation', () => {
      const source = 'result = reduce data by unknown';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());

      expect(() => parser.parse()).toThrow('Unknown reduction operation');
    });
  });

  describe('Output Statements', () => {
    it('should parse output statement', () => {
      const source = 'output result';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      expect(ast.statements[0]!.type).toBe('output');
      if (ast.statements[0]!.type === 'output') {
        expect(ast.statements[0].source).toBe('result');
      }
    });
  });

  describe('Error Handling', () => {
    it('should throw on unexpected token at statement level', () => {
      const source = '123';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());

      expect(() => parser.parse()).toThrow('Unexpected token');
    });

    it('should throw on missing assignment operator', () => {
      const source = 'result filter data where x > 0';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());

      expect(() => parser.parse()).toThrow();
    });

    it('should throw on missing WHERE keyword', () => {
      const source = 'result = filter data x > 0';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());

      expect(() => parser.parse()).toThrow('Expected WHERE');
    });

    it('should throw on missing WITH keyword', () => {
      const source = 'result = map data x * 2';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());

      expect(() => parser.parse()).toThrow('Expected WITH');
    });

    it('should throw on missing BY keyword', () => {
      const source = 'result = reduce data sum';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());

      expect(() => parser.parse()).toThrow('Expected BY');
    });
  });

  describe('Complex Expressions', () => {
    it('should parse complete pipeline', () => {
      const source = `
input data: number[]
filtered = filter data where x > 0
mapped = map filtered with x * 2
result = reduce mapped by sum
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      expect(ast.statements).toHaveLength(5);
      expect(ast.statements[0]!.type).toBe('input');
      expect(ast.statements[1]!.type).toBe('filter');
      expect(ast.statements[2]!.type).toBe('map');
      expect(ast.statements[3]!.type).toBe('reduce');
      expect(ast.statements[4]!.type).toBe('output');
    });

    it('should parse multiple filters', () => {
      const source = `
input data: number[]
positive = filter data where x > 0
even = filter positive where x % 2 == 0
output even
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      expect(ast.statements).toHaveLength(4);
      expect(ast.statements[1]!.type).toBe('filter');
      expect(ast.statements[2]!.type).toBe('filter');
    });
  });
});

describe('ASTToGraphConverter', () => {
  describe('Basic Conversions', () => {
    it('should convert input declaration', () => {
      const source = 'input data: number[]';
      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);

      expect(graph).toBeDefined();
    });

    it('should convert filter statement', () => {
      const source = `
input data: number[]
filtered = filter data where x > 10
output filtered
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      const result = compiledFn([5, 15, 8, 20]);
      expect(result).toEqual([15, 20]);
    });

    it('should convert map statement', () => {
      const source = `
input data: number[]
doubled = map data with x * 2
output doubled
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      const result = compiledFn([1, 2, 3]);
      expect(result).toEqual([2, 4, 6]);
    });

    it('should convert reduce statement', () => {
      const source = `
input data: number[]
total = reduce data by sum
output total
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      const result = compiledFn([1, 2, 3, 4]);
      expect(result).toBe(10);
    });
  });

  describe('Complex Pipelines', () => {
    it('should handle filter-map-reduce pipeline', () => {
      const source = `
input numbers: number[]
positive = filter numbers where x > 0
doubled = map positive with x * 2
total = reduce doubled by sum
output total
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      const result = compiledFn([1, -2, 3, -4, 5]);
      expect(result).toBe(18); // (1 + 3 + 5) * 2 = 18
    });

    it('should handle property access in filters', () => {
      const source = `
input users: object[]
adults = filter users where x.age >= 18
output adults
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      const users = [
        { name: 'Alice', age: 25 },
        { name: 'Bob', age: 15 },
        { name: 'Charlie', age: 30 },
      ];

      const result = compiledFn(users);
      expect(result).toHaveLength(2);
      expect(result[0].name).toBe('Alice');
      expect(result[1].name).toBe('Charlie');
    });

    it('should handle property extraction in maps', () => {
      const source = `
input users: object[]
names = map users with x.name
output names
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      const users = [
        { name: 'Alice', age: 25 },
        { name: 'Bob', age: 30 },
      ];

      const result = compiledFn(users);
      expect(result).toEqual(['Alice', 'Bob']);
    });
  });

  describe('Arithmetic Operations', () => {
    it('should handle all arithmetic operators', () => {
      const testCases = [
        { op: 'x + 5', input: [1, 2, 3], expected: [6, 7, 8] },
        { op: 'x - 5', input: [10, 20, 30], expected: [5, 15, 25] },
        { op: 'x * 3', input: [1, 2, 3], expected: [3, 6, 9] },
        { op: 'x / 2', input: [10, 20, 30], expected: [5, 10, 15] },
        { op: 'x % 3', input: [10, 11, 12], expected: [1, 2, 0] },
      ];

      testCases.forEach(({ op, input, expected }) => {
        const source = `
input data: number[]
result = map data with ${op}
output result
        `.trim();

        const lexer = new Lexer(source);
        const parser = new Parser(lexer.tokenize());
        const ast = parser.parse();

        const converter = new ASTToGraphConverter();
        const graph = converter.convert(ast);
        const compiledFn = graph.compile();

        const result = compiledFn(input);
        expect(result).toEqual(expected);
      });
    });
  });

  describe('Reduction Operations', () => {
    it('should handle sum reduction', () => {
      const source = `
input data: number[]
total = reduce data by sum
output total
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([1, 2, 3, 4])).toBe(10);
    });

    it('should handle max reduction', () => {
      const source = `
input data: number[]
maximum = reduce data by max
output maximum
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([3, 7, 2, 9, 1])).toBe(9);
    });

    it('should handle min reduction', () => {
      const source = `
input data: number[]
minimum = reduce data by min
output minimum
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([3, 7, 2, 9, 1])).toBe(1);
    });

    it('should handle count reduction', () => {
      const source = `
input data: number[]
cnt = reduce data by count
output cnt
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([1, 2, 3, 4, 5])).toBe(5);
    });
  });

  describe('String Operations', () => {
    it('should handle uppercase transform', () => {
      const source = `
input words: string[]
upper = map words with uppercase(x)
output upper
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn(['hello', 'world'])).toEqual(['HELLO', 'WORLD']);
    });

    it('should handle lowercase transform', () => {
      const source = `
input words: string[]
lower = map words with lowercase(x)
output lower
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn(['HELLO', 'WORLD'])).toEqual(['hello', 'world']);
    });

    it('should handle trim transform', () => {
      const source = `
input words: string[]
trimmed = map words with trim(x)
output trimmed
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn(['  hello  ', '  world  '])).toEqual(['hello', 'world']);
    });
  });

  describe('Error Handling', () => {
    it('should throw on undefined variable', () => {
      const source = `
input data: number[]
result = map nonexistent with x * 2
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      expect(() => converter.convert(ast)).toThrow('Undefined variable');
    });
  });

  describe('Arithmetic Predicates', () => {
    it('should parse modulo predicate for even numbers', () => {
      const source = `
input numbers: number[]
evens = filter numbers where x % 2 == 0
output evens
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const filterStmt = ast.statements[1];
      expect(filterStmt!.type).toBe('filter');
      if (filterStmt!.type === 'filter') {
        expect(filterStmt!.predicate.type).toBe('arithmetic');
        if (filterStmt.predicate.type === 'arithmetic') {
          expect(filterStmt!.predicate.arithmeticOp).toBe('mod');
          expect(filterStmt!.predicate.arithmeticValue).toBe(2);
          expect(filterStmt!.predicate.comparisonOp).toBe('eq');
          expect(filterStmt!.predicate.comparisonValue).toBe(0);
        }
      }
    });

    it('should compile and execute modulo predicate', () => {
      const source = `
input numbers: number[]
evens = filter numbers where x % 2 == 0
output evens
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([1, 2, 3, 4, 5, 6])).toEqual([2, 4, 6]);
    });

    it('should parse multiplication predicate', () => {
      const source = `
input numbers: number[]
result = filter numbers where x * 3 > 10
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const filterStmt = ast.statements[1];
      if (filterStmt!.type === 'filter' && filterStmt!.predicate.type === 'arithmetic') {
        expect(filterStmt!.predicate.arithmeticOp).toBe('multiply');
        expect(filterStmt!.predicate.arithmeticValue).toBe(3);
        expect(filterStmt!.predicate.comparisonOp).toBe('gt');
        expect(filterStmt!.predicate.comparisonValue).toBe(10);
      }
    });

    it('should compile and execute multiplication predicate', () => {
      const source = `
input numbers: number[]
result = filter numbers where x * 3 > 10
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([1, 2, 3, 4, 5])).toEqual([4, 5]);
    });

    it('should parse addition predicate', () => {
      const source = `
input numbers: number[]
result = filter numbers where x + 5 < 20
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const filterStmt = ast.statements[1];
      if (filterStmt!.type === 'filter' && filterStmt!.predicate.type === 'arithmetic') {
        expect(filterStmt!.predicate.arithmeticOp).toBe('add');
        expect(filterStmt!.predicate.arithmeticValue).toBe(5);
        expect(filterStmt!.predicate.comparisonOp).toBe('lt');
        expect(filterStmt!.predicate.comparisonValue).toBe(20);
      }
    });

    it('should parse subtraction predicate', () => {
      const source = `
input numbers: number[]
result = filter numbers where x - 10 >= 0
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const filterStmt = ast.statements[1];
      if (filterStmt!.type === 'filter' && filterStmt!.predicate.type === 'arithmetic') {
        expect(filterStmt!.predicate.arithmeticOp).toBe('subtract');
        expect(filterStmt!.predicate.arithmeticValue).toBe(10);
        expect(filterStmt!.predicate.comparisonOp).toBe('gte');
        expect(filterStmt!.predicate.comparisonValue).toBe(0);
      }
    });

    it('should parse division predicate', () => {
      const source = `
input numbers: number[]
result = filter numbers where x / 2 <= 5
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const filterStmt = ast.statements[1];
      if (filterStmt!.type === 'filter' && filterStmt!.predicate.type === 'arithmetic') {
        expect(filterStmt!.predicate.arithmeticOp).toBe('divide');
        expect(filterStmt!.predicate.arithmeticValue).toBe(2);
        expect(filterStmt!.predicate.comparisonOp).toBe('lte');
        expect(filterStmt!.predicate.comparisonValue).toBe(5);
      }
    });

    it('should parse not equals arithmetic predicate', () => {
      const source = `
input numbers: number[]
result = filter numbers where x % 3 != 0
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const filterStmt = ast.statements[1];
      if (filterStmt!.type === 'filter' && filterStmt!.predicate.type === 'arithmetic') {
        expect(filterStmt!.predicate.comparisonOp).toBe('neq');
      }
    });

    it('should compile and execute not equals arithmetic predicate', () => {
      const source = `
input numbers: number[]
result = filter numbers where x % 3 != 0
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([1, 2, 3, 4, 5, 6, 7, 8, 9])).toEqual([1, 2, 4, 5, 7, 8]);
    });

    it('should handle negative arithmetic values', () => {
      const source = `
input numbers: number[]
result = filter numbers where x * -1 < 0
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([1, -2, 3, -4, 5])).toEqual([1, 3, 5]);
    });

    it('should handle decimal arithmetic values', () => {
      const source = `
input numbers: number[]
result = filter numbers where x * 0.5 > 1
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([1, 2, 3, 4, 5])).toEqual([3, 4, 5]);
    });

    it('should work in complex pipeline with arithmetic predicates', () => {
      const source = `
input numbers: number[]
evens = filter numbers where x % 2 == 0
doubled = map evens with x * 2
total = reduce doubled by sum
output total
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      // Input: [1, 2, 3, 4, 5, 6]
      // Filter evens: [2, 4, 6]
      // Double: [4, 8, 12]
      // Sum: 24
      expect(compiledFn([1, 2, 3, 4, 5, 6])).toBe(24);
    });
  });

  describe('Arithmetic Predicate Edge Cases', () => {
    it('should handle parsing error for invalid arithmetic operator', () => {
      const source = `
input numbers: number[]
result = filter numbers where x @ 2 == 0
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());

      // Should throw error due to invalid operator @
      expect(() => parser.parse()).toThrow();
    });

    it('should parse arithmetic with very large numbers', () => {
      const source = `
input numbers: number[]
result = filter numbers where x * 1000000 > 5000000
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([1, 10, 100])).toEqual([10, 100]);
    });

    it('should parse arithmetic with very small decimal numbers', () => {
      const source = `
input numbers: number[]
result = filter numbers where x * 0.001 < 1
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([100, 1000, 10000])).toEqual([100]);
    });

    it('should handle parseNumericValue with explicit positive sign edge case', () => {
      // Note: The lexer may not support + prefix, but we test the number parsing
      const source = `
input numbers: number[]
result = filter numbers where x + 5 == 10
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([5, 10, 15])).toEqual([5]);
    });

    it('should handle zero in arithmetic operations correctly', () => {
      const source = `
input numbers: number[]
result = filter numbers where x - 0 == 5
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([5, 0, -5])).toEqual([5]);
    });

    it('should parse multiple arithmetic predicates in sequence', () => {
      const source = `
input numbers: number[]
evens = filter numbers where x % 2 == 0
multiples_of_three = filter numbers where x % 3 == 0
result = filter numbers where x % 6 == 0
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([6, 12, 15, 18, 20])).toEqual([6, 12, 18]);
    });

    it('should handle arithmetic predicate with negative comparison value', () => {
      const source = `
input numbers: number[]
result = filter numbers where x + 10 > -5
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([-20, -15, -10, 0])).toEqual([-15, -10, 0]);
    });

    it('should parse and execute arithmetic in map operations', () => {
      const source = `
input numbers: number[]
filtered = filter numbers where x % 2 == 0
mapped = map filtered with x * 3
output mapped
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([1, 2, 3, 4, 5, 6])).toEqual([6, 12, 18]);
    });

    it('should handle chained arithmetic operations', () => {
      const source = `
input numbers: number[]
step1 = filter numbers where x % 2 == 0
step2 = filter step1 where x % 3 == 0
output step2
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      // Should find numbers divisible by both 2 and 3 (i.e., divisible by 6)
      expect(compiledFn([2, 3, 6, 9, 12, 15, 18])).toEqual([6, 12, 18]);
    });

    it('should parse arithmetic with all comparison operators systematically', () => {
      const operators = ['>', '<', '>=', '<=', '==', '!='];

      operators.forEach((op) => {
        const source = `
input numbers: number[]
result = filter numbers where x % 5 ${op} 0
output result
        `.trim();

        const lexer = new Lexer(source);
        const parser = new Parser(lexer.tokenize());

        // Should parse without errors
        expect(() => parser.parse()).not.toThrow();
      });
    });

    it('should handle fractional results in division arithmetic', () => {
      const source = `
input numbers: number[]
result = filter numbers where x / 3 > 2.5
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([6, 7, 8, 9, 10])).toEqual([8, 9, 10]);
    });

    it('should preserve precision in modulo with decimals', () => {
      const source = `
input numbers: number[]
result = filter numbers where x % 2.5 == 0
output result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([2.5, 5, 7.5, 10])).toEqual([2.5, 5, 7.5, 10]);
    });
  });

  describe('Parser Integration with Arithmetic', () => {
    it('should handle arithmetic predicates in complex nested pipelines', () => {
      const source = `
input data: number[]
positive = filter data where x > 0
evens = filter positive where x % 2 == 0
large = filter evens where x > 10
doubled = map large with x * 2
total = reduce doubled by sum
output total
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      // positive: [2,4,12,14,20] -> evens: [2,4,12,14,20] -> large: [12,14,20] -> doubled: [24,28,40] -> sum: 92
      expect(compiledFn([-5, 2, 4, 12, 14, 20])).toBe(92);
    });

    it('should work with arithmetic predicates and property access', () => {
      const source = `
input items: object[]
filtered = filter items where age % 10 == 0
output filtered
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      const testData = [
        { name: 'Alice', age: 20 },
        { name: 'Bob', age: 25 },
        { name: 'Charlie', age: 30 },
        { name: 'David', age: 35 },
      ];

      expect(compiledFn(testData)).toEqual([
        { name: 'Alice', age: 20 },
        { name: 'Charlie', age: 30 },
      ]);
    });

    it('should handle arithmetic predicates with reduction operations', () => {
      const source = `
input numbers: number[]
multiples = filter numbers where x % 3 == 0
count_result = reduce multiples by count
output count_result
      `.trim();

      const lexer = new Lexer(source);
      const parser = new Parser(lexer.tokenize());
      const ast = parser.parse();

      const converter = new ASTToGraphConverter();
      const graph = converter.convert(ast);
      const compiledFn = graph.compile();

      expect(compiledFn([1, 3, 6, 9, 11, 12, 15])).toBe(5);
    });
  });
});
